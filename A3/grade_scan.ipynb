{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This file creates the final csv which can be upload to the moodle named as moodle_gradeA2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir: str = os.getcwd()\n",
    "logs_dir: str = os.path.join(home_dir, 'logs')\n",
    "plot_dir: str = os.path.join(home_dir, 'plots')\n",
    "sub_dir: str = os.path.join(home_dir, 'subA3')\n",
    "info_task1_dir: str = os.path.join(home_dir, 'info_task1')\n",
    "info_task2_dir: str = os.path.join(home_dir, 'info_task2') \n",
    "results_dir: str = os.path.join(home_dir, 'results')\n",
    "\n",
    "print (home_dir, logs_dir, plot_dir, sub_dir, results_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40% of correctness, 40% of performnace, and 20% of report\n",
    "final_scaling = {\n",
    "    'report': 1.8 / 100, \n",
    "    'correctness': 3.6 / 100, \n",
    "    'performance': 3.6 / 100,\n",
    "}\n",
    "final_scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get kerberos from the entry number and also the group ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kerberos(Entry_no: str) -> str:\n",
    "    year, dept, endwith = Entry_no[2: 4], Entry_no[4: 7], Entry_no[7: ]\n",
    "    kerberos = dept + year + endwith\n",
    "    return kerberos.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the pairs of students who are doing assignment in pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_pair_df = pd.read_csv(os.path.join(home_dir, 'studentPairs.csv'))\n",
    "# student_pair_df.set_index('studentA', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights of scan, since they are default /100 for each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_report = {\n",
    "    'Table': 0.3,\n",
    "    'Scan' : 0.2, \n",
    "    'Plots' : 0.2,\n",
    "    'Iso-efficiency-and-Seq-Frac' : 0.3\n",
    "} # Update these accordingly \n",
    "\n",
    "scan_df = pd.read_csv(os.path.join(home_dir, 'report_scores.csv'))\n",
    "scan_df['Total Score'] = 0\n",
    "for metric in weight_report.keys():\n",
    "    scan_df['Total Score'] += scan_df[metric] * weight_report[metric]\n",
    "# need_demo = scan_df[scan_df['Demo required'] == 'Need demo']['Entry Number']\n",
    "# need_demo.to_csv(os.path.join(home_dir, 'need_demo.csv'))\n",
    "scan_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a format for comment to pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalty_df = pd.read_csv(os.path.join(home_dir, 'demo_penalty.csv'))\n",
    "# penalty_df.set_index('email_address', inplace=True)\n",
    "\n",
    "# demo_students = list(penalty_df.index)\n",
    "# demo_students = [eno.split('@')[0] for eno in demo_students]\n",
    "\n",
    "# def get_penalty(entry_no):\n",
    "#     return 0.75 * penalty_df.loc[f'{entry_no}@cse.iitd.ac.in', 'penalty']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all three type of scores and some renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read all three components\n",
    "correct_df = pd.read_csv(os.path.join(results_dir, 'correctness.csv'))\n",
    "performance_df = pd.read_csv(os.path.join(results_dir, 'runtime_score.csv'))\n",
    "\n",
    "# 2. Some renaming for better readability\n",
    "correct_df.rename(columns={'Total Score': 'TOTAL CORRECTNESS SCORE(out of 100)'}, inplace=True)\n",
    "scan_df.rename(columns={'Total Score': 'TOTAL REPORT SCORE(out of 100)'}, inplace=True)\n",
    "performance_df.rename(columns={'Total Score': 'TOTAL PERFORMANCE SCORE(out of 100)'}, inplace=True)\n",
    "\n",
    "# correct_df.set_index('kerberos', inplace=True)\n",
    "# performance_df.set_index('kerberos', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling information to the comment for the moodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some renaming\n",
    "# scan_df = scan_df.replace(np.nan, 'No')\n",
    "# scan_df.drop(columns='Demo required ?', inplace=True)\n",
    "comments = {k: {} for k in list(correct_df['kerberos'])}\n",
    "print(correct_df.columns)\n",
    "\n",
    "paired_to = dict()\n",
    "for _, row in student_pair_df.iterrows():\n",
    "    paired_to[row['studentA']] = row['group']\n",
    "    paired_to[row['studentB']] = row['group']\n",
    "    \n",
    "# 1. Then find fill down details for correctness\n",
    "for _, student in correct_df.iterrows():\n",
    "    correctness_marks = dict()\n",
    "    Entry_no = student['kerberos']\n",
    "    for cols in correct_df.columns:\n",
    "        if cols == 'Entry_no' or cols == 'kerberos':\n",
    "            continue\n",
    "        correctness_marks[cols] = student[cols]\n",
    "    print (f'Entry no: {Entry_no}, marks: {correctness_marks}')\n",
    "    comments[Entry_no]['correctness'] = correctness_marks\n",
    "    \n",
    "# 2. Scan marks\n",
    "print (scan_df.columns)\n",
    "for _, student in scan_df.iterrows():\n",
    "    report_marks = dict() \n",
    "    Entry_no = get_kerberos(student['Entry_no'])\n",
    "    for cols in scan_df.columns:\n",
    "        if cols == 'Entry_no' or cols == 'kerberos':\n",
    "            continue\n",
    "        report_marks[cols] = student[cols]\n",
    "    comments[Entry_no]['report'] = report_marks\n",
    "\n",
    "# 3. Performance marks\n",
    "print (performance_df.columns)\n",
    "for _, student in performance_df.iterrows():\n",
    "    performance_marks = dict() \n",
    "    Entry_no = student['kerberos']\n",
    "\n",
    "    for cols in performance_df.columns:\n",
    "        if cols == 'Entry_no' or cols == 'kerberos':\n",
    "            continue\n",
    "        performance_marks[cols] = student[cols] \n",
    "    comments[Entry_no]['performance'] = performance_marks\n",
    "\n",
    "pprint(comments)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the final csv, which will be upload to moodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the students who are active on moodle \n",
    "moodle_export_df = pd.read_csv(os.path.join(home_dir, 'col380exports.csv'))\n",
    "# Final dataframe : grades going to publish to moodle, is filled to this.\n",
    "moodle_csv = {'userid': [], 'marks': [], 'comments': []}\n",
    "\n",
    "print (set(comments.keys()) - set(paired_to.keys()))\n",
    "\n",
    "for Entry_no, comment in comments.items():\n",
    "    Entry_no = Entry_no.lower()\n",
    "    \n",
    "    groupid = paired_to[Entry_no]\n",
    "    groupid = groupid.lower()\n",
    "    studentA, studentB = \"\", \"\"\n",
    "    if '_' in groupid:\n",
    "        studentA, studentB = groupid.split('_')\n",
    "    else:\n",
    "        studentA = studentB = groupid\n",
    "    studentA = studentA.strip().lower()\n",
    "    studentB = studentB.strip().lower()\n",
    "    if Entry_no == 'cs1190452':\n",
    "        print (f'Yes, {studentA}, {studentB} and {groupid}')\n",
    "    \n",
    "    print (f'StudentA = {studentA}, studentB = {studentB}') \n",
    "\n",
    "    penalty = 0.0\n",
    "    # if (studentA in demo_students):\n",
    "    #     penalty = get_penalty(studentA)\n",
    "    # if (studentB in demo_students):\n",
    "    #     penalty = get_penalty(studentB)\n",
    "    # comment['penalty_for_demo'] = penalty\n",
    "\n",
    "    # Final global scaling of marks \n",
    "    scaled_correctness_score = comment['correctness']['TOTAL CORRECTNESS SCORE(out of 100)'] * final_scaling['correctness']\n",
    "    scaled_performance_score = comment['performance']['TOTAL PERFORMANCE SCORE(out of 100)'] * final_scaling['performance']\n",
    "    scaled_report_score = comment['report']['TOTAL REPORT SCORE(out of 100)'] * final_scaling['report']\n",
    "\n",
    "    if 'report' not in comment:\n",
    "        print (f\"Yes : {studentA}, {studentB}\")\n",
    "        comment['report'] = {}\n",
    "        comment['report']['TOTAL REPORT SCORE(out of 100)'] = np.nan\n",
    "\n",
    "    marks = scaled_report_score + max(0, scaled_correctness_score + scaled_performance_score - penalty)\n",
    "    marks = round(marks, 2)\n",
    "    if studentA == studentB:\n",
    "        moodle_csv['userid'].append(studentA)\n",
    "        moodle_csv['marks'].append(marks)\n",
    "        moodle_csv['comments'].append(comment)\n",
    "    else:\n",
    "        moodle_csv['userid'].extend([studentA, studentB])\n",
    "        moodle_csv['marks'].extend([marks, marks])\n",
    "        moodle_csv['comments'].extend([comment, comment])\n",
    "\n",
    "\n",
    "print(moodle_csv)    \n",
    "\n",
    "alluserid = set(list(moodle_export_df['ID number']))\n",
    "submitted = set(list(moodle_csv['userid']))\n",
    "print (f'Total user on moodle avail {alluserid}, how many submitted = {submitted}')\n",
    "\n",
    "notsubmitted = alluserid - submitted\n",
    "dropcourse = submitted - alluserid \n",
    "commons = (dropcourse) and (notsubmitted)\n",
    "\n",
    "pprint (f'len: {len(commons)}, Commons: {commons}')\n",
    "pprint (f'len: {len(notsubmitted)} Not sumbitted: {notsubmitted}')\n",
    "pprint (f'len: {len(dropcourse)} Dropped : {dropcourse}')\n",
    "\n",
    "for e in notsubmitted:\n",
    "    moodle_csv['userid'].append(e)\n",
    "    moodle_csv['marks'].append(0)\n",
    "    moodle_csv['comments'].append('Not Submitted')\n",
    "\n",
    "moodle_csv = pd.DataFrame(moodle_csv)\n",
    "moodle_csv.set_index('userid', inplace=True)\n",
    "\n",
    "for e in dropcourse:\n",
    "    moodle_csv.drop(e, inplace=True)\n",
    "\n",
    "moodle_csv.to_csv(os.path.join(results_dir, 'gradesA3.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats for the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv(os.path.join(results_dir, 'gradesA3.csv'))\n",
    "marks = stats_df[stats_df['comments'] != 'Not Submitted']['marks']\n",
    "userids = stats_df[stats_df['comments'] != 'Not Submitted']['userid']\n",
    "distribution = marks.describe()\n",
    "print(distribution)\n",
    "pprint (marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topScores = pd.Series(marks.nlargest(18).unique())\n",
    "print (len(topScores))\n",
    "print (f'Stats for top 20: {topScores.describe()}')\n",
    "topScores = pd.Series(marks.nlargest(37).unique())\n",
    "print (len(topScores))\n",
    "print (f'Stats for top 20: {topScores.describe()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
